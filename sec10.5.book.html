<!doctype html>
<html lang="en-US" xml:lang="en-US">
	<head>
		<title>10.5 Constant Coefficient Homogeneous Systems II</title>
		<meta charset="utf-8" />
		<meta content="TeX4ht (https://tug.org/tex4ht/)" name="generator" />
		<meta content="width=device-width,initial-scale=1" name="viewport" />
		<link rel="stylesheet" type="text/css" href="combined.css" />
		<meta content="Trench_DiffEQ_Book.tex" name="src" />
		<script>
			window.MathJax = {
				tex: { packages: { "[+]": ["tagformat"] }, tags: "ams", tagformat: { tag: (tag) => "(10.5." + tag + ")" } },
			};
		</script>
		<script async="async" id="MathJax-script" src="mathjax-3-es5-tex-chtml-full.js" type="text/javascript"></script>
		<style type="text/css">
			:root {
				--section-number: "10.5";
			}
		</style>
		<script type="text/javascript" src="niceties.js"></script>
	</head>

	<body>
		<div style="display: none" id="b894547c-f3b6-489f-a1d9-56febe1bb072">
			\( 
				\newcommand{\threecol}[3]{\left(\begin{array}{r}#1\\#2\\#3\end{array}\right)}
				\newcommand{\twocol}[2]{\left(\begin{array}{c}#1\\#2\end{array}\right)}
				\newcommand{\twochar}[4]{\left| \begin {array}{cc} #1-\lambda&amp; #2\\#3&amp; #4-\lambda \end{array}\right|}
				\newcommand{\twobytwo}[4]{\left( \begin {array}{rr} #1&amp; #2\\#3&amp; #4 \end{array}\right)}
				\newcommand{\threebythree}[9]{\left( \begin {array}{rrr} #1&amp; #2&amp; #3\\#4&amp; #5&amp; #6\\#7&amp; #8&amp; #9 \end{array}\right)}
				\newcommand{\matfunc}[3]{\left( \begin {array}{cccc}#1_{11}(t)&amp; #1_{12}(t)&amp;\cdots &amp; #1_{1#3}(t)\\#1_{21}(t)&amp; #1_{22}(t)&amp;\cdots&amp; #1_{2#3}(t)\\\vdots&amp; \vdots&amp;\ddots&amp;\vdots\\#1_{#21}(t)&amp; #1_{#22}(t)&amp;\cdots&amp; #1_{#2#3}(t) \end{array}\right)}
				\newcommand{\col}[2]{\left(\begin{array}{c}#1_1\\#1_2\\\vdots\\#1_#2\end{array}\right)}
				\newcommand{\colfunc}[2]{\left( \begin {array}{c}#1_1(t)\\#1_2(t)\\\vdots\\#1_#2(t) \end{array}\right) }
				\newcommand{\cthreebythree}[9]{\left( \begin {array}{ccc} #1&amp; #2&amp; #3\\#4&amp; #5&amp; #6\\#7&amp; #8&amp; #9  \end{array}\right)} 
			\) 
		</div>
		<div id="7c02b686-8ce9-49dc-9d68-7ffd7ef81e1b" class="section-title">
			 10.5 Constant Coefficient Homogeneous Systems II 
		</div>

		<details id="details-1">
			<summary>Repeated Eigenvalues</summary>

			<div id="34d411f8-5671-4023-9222-26a5412ae85b">
				We saw in Section&nbsp;10.4 that if an \(n\times n\) constant matrix \(A\) has \(n\) real eigenvalues \(\lambda _1\), \(\lambda _2\), …, \(\lambda _n\) (which need not be distinct) with associated linearly independent eigenvectors \({\bf \vec{x}}_1\), \({\bf \vec{x}}_2\), …, \({\bf \vec{x}}_n\), then the general solution of \(\dfrac{d{\bf \vec{y}}}{dt}=A{\bf \vec{y}}\) is 
				\[ {\bf \vec{y}}=c_1{\bf \vec{x}}_1e^{\lambda _1t}+c_2{\bf \vec{x}}_2e^{\lambda _2 t} +\cdots +c_n{\bf \vec{x}}_ne^{\lambda _n t} \] 
				
				In this section we consider the case where \(A\) has \(n\) real eigenvalues, but does not have \(n\) linearly independent eigenvectors. It is shown in linear algebra that this occurs if and only if \(A\) has at least one eigenvalue of multiplicity \(r&gt;1\) such that the associated eigenspace has dimension less than \(r\). In this case \(A\) is said to be <span class="vocab">defective</span>. Since it’s beyond the scope of this book to give a complete analysis of systems with defective coefficient matrices, we will restrict our attention to some commonly occurring special cases. 
			</div>
			<div class="example" id="x1-21" style="--ex-number: 1">
				<div>
					Show that the system 

					<a id="x1-3r1"></a>
					\begin {equation} 
						\label {eq:10.5.1} 
						\dfrac{d{\bf \vec{y}}}{dt}=\twobytwo {11}{-25}4{-9}{\bf \vec{y}} 
					\end {equation}
					
					does not have a fundamental set of solutions of the form \(\{{\bf \vec{x}}_1e^{\lambda _1t},{\bf \vec{x}}_2e^{\lambda _2t}\}\), where \(\lambda _1\) and \(\lambda _2\) are eigenvalues of the coefficient matrix \(A\) of <a href="#x1-3r1">(10.5.1)</a> and \({\bf \vec{x}}_1\), and \({\bf \vec{x}}_2\) are associated linearly independent eigenvectors.
				</div>

				<details class="solution">
					<summary>Solution</summary>
					The characteristic polynomial of \(A\) is 

					<div class="eqnarray" id="fb4bfdae-3e65-44b2-819c-e1c077cd8703">
						\begin {eqnarray*}
							\twochar {11}{-25}4{-9} &amp;=&amp;(\lambda -11)(\lambda +9)+100\\ 
							&amp;=&amp;\lambda ^2-2\lambda +1=(\lambda -1)^2 
						\end {eqnarray*} 
					</div>
					Hence, \(\lambda =1\) is the only eigenvalue of \(A\). The augmented matrix of the system \((A-I){\bf \vec{x}}={\bf 0}\) is 
					\[ \left [
						\begin {array}{rrcr}
							10&amp;-25&amp;\vdots&amp; 0\\
							4&amp; -10&amp;\vdots&amp; 0
						\end {array}
					\right ]\] 
					
					which is row equivalent to 
					\[ \left [ 
						\begin {array}{rrcr}
							1&amp;-\displaystyle {5\over 2}&amp;\vdots&amp; 0\\
							0&amp; 0&amp;\vdots&amp; 0 
						\end {array}
					\right ]\] 
					
					Hence, \(x_1=5x_2/2\) where \(x_2\) is arbitrary. Therefore all eigenvectors of \(A\) are scalar multiples of \({\bf \vec{x}}_1=\displaystyle {\twocol 52}\), so \(A\) does not have a set of two linearly independent eigenvectors.
				</details>
			</div>

			<div id="637fe797-850e-4555-a5ef-242d62b29dd0">
				From Example&nbsp;<a href="#x1-21">10.5.1</a>, we know that all scalar multiples of \({\bf \vec{y}}_1=\displaystyle {\twocol 52}e^t\) are solutions of <a href="#x1-3r1">(10.5.1)</a>; however, to find the general solution we must find a second solution \({\bf \vec{y}}_2\) such that \(\{{\bf \vec{y}}_1,{\bf \vec{y}}_2\}\) is linearly independent. Based on your recollection of the procedure for solving a constant coefficient scalar equation 
				\[ a\dfrac{d^2y}{dt^2}+b\dfrac{dy}{dt}+cy=0 \]
				
				in the case where the characteristic polynomial has a repeated root, you might expect to obtain a second solution of <a href="#x1-3r1">(10.5.1)</a> by multiplying the first solution by \(t\). However, this yields \({\bf \vec{y}}_2=\displaystyle {\twocol 52}te^t\), which doesn’t work, since 
				\[ \dfrac{d{\bf \vec{y}}_2}{dt} = \twocol 52(te^t+e^t),\quad \mbox{ while } \quad \twobytwo {11}{-25}4{-9}{\bf \vec{y}}_2=\twocol 52te^t\]
			</div>

			<div id="edd5997f-eedd-4b79-9e44-1c1f5a139fec">
				The next theorem shows what to do in this situation. 
			</div>

			<div class="theorem" id="x1-41">
				<span class="head">Theorem&nbsp;10.5.1</span>
				Suppose the \(n\times n\) matrix \(A\) has an eigenvalue \(\lambda _1\) of multiplicity \(\ge 2\) and the associated eigenspace has dimension \(1;\) that is, all \(\lambda _1\)-eigenvectors of \(A\) are scalar multiples of an eigenvector \({\bf \vec{x}}.\) Then there are infinitely many vectors \(\bf u\) such that 
				
				<a id="x1-5r2"></a>
				\begin {equation} 
					\label {eq:10.5.2} 
					(A-\lambda _1I){\bf \vec{u}}={\bf \vec{x}} 
				\end {equation}
				
				Moreover, if \(\bf u\) is any such vector then 
				
				<a id="x1-6r3"></a>
				\begin {equation} 
					\label {eq:10.5.3} 
					{\bf \vec{y}}_1={\bf \vec{x}}e^{\lambda _1t}\quad \mbox {and }\quad {\bf \vec{y}}_2={\bf \vec{u}}e^{\lambda _1t}+{\bf \vec{x}}te^{\lambda _1t} 
				\end {equation}
				
				are linearly independent solutions of \(\dfrac{d{\bf \vec{y}}}{dt}=A{\bf \vec{y}}.\)
			</div>

			<div id="deb5f245-266e-424e-a605-65e4b5995579">
				A complete proof of this theorem is beyond the scope of this book. The difficulty is in proving that there’s a vector \(\bf u\) satisfying <a href="#x1-5r2">(10.5.2)</a>, since \(\det (A-\lambda _1I)=0\). We’ll take this without proof and verify the other assertions of the theorem.
			</div>

			<div id="5771adba-8ada-486b-a623-7bbca4f512e4">
				We already know that \({\bf \vec{y}}_1\) in <a href="#x1-6r3">(10.5.3)</a> is a solution of \(\dfrac{d{\bf \vec{y}}}{dt}=A{\bf \vec{y}}\). To see that \({\bf \vec{y}}_2\) is also a solution, we compute
			</div>

			<div class="eqnarray" id="fd388160-95c2-47ae-9eef-d588b56ab51c">
				\begin {eqnarray*}
					\dfrac{{\bf \vec{y}}_2}{dt} - A{\bf \vec{y}}_2&amp;=&amp;\lambda _1{\bf \vec{u}}e^{\lambda _1t}+{\bf \vec{x}} e^{\lambda _1t} +\lambda _1{\bf \vec{x}} te^{\lambda _1t}-A{\bf \vec{u}}e^{\lambda _1t}-A{\bf \vec{x}} te^{\lambda _1t}\\
					&amp;=&amp;(\lambda _1{\bf \vec{u}}+{\bf \vec{x}} -A{\bf \vec{u}})e^{\lambda _1t}+(\lambda _1{\bf \vec{x}} -A{\bf \vec{x}} )te^{\lambda _1t} 
				\end {eqnarray*} 
			</div>

			<div id="4f66ef3b-bdd6-48c2-8742-108a991e6154">
				Since \(A{\bf \vec{x}}=\lambda _1{\bf \vec{x}}\), this can be written as 
				\[ \dfrac{{\bf \vec{y}}_2}{dt} - A{\bf \vec{y}}_2=- \left ((A-\lambda _1I){\bf \vec{u}}-{\bf \vec{x}}\right )e^{\lambda _1t}\] 
				
				and now <a href="#x1-5r2">(10.5.2)</a> implies that \( \dfrac{{\bf \vec{y}}_2}{dt} = A{\bf \vec{y}}_2\).
			</div>

			<div id="4267adeb-f5f5-4ffc-b28f-cdda2b70450f">
				To see that \({\bf \vec{y}}_1\) and \({\bf \vec{y}}_2\) are linearly independent, suppose \(c_1\) and \(c_2\) are constants such that 
				
				<a id="x1-7r4"></a>
				\begin {equation} 
					\label {eq:10.5.4} 
					c_1{\bf \vec{y}}_1+c_2{\bf \vec{y}}_2=c_1{\bf \vec{x}}e^{\lambda _1t}+c_2({\bf \vec{u}}e^{\lambda _1t} +{\bf \vec{x}}te^{\lambda _1t})={\bf 0} 
				\end {equation}
				
				We must show that \(c_1=c_2=0\). Multiplying <a href="#x1-7r4">(10.5.4)</a> by \(e^{-\lambda _1t}\) shows that 
				
				<a id="x1-8r5"></a>
				\begin {equation} 
					\label {eq:10.5.5} 
					c_1{\bf \vec{x}}+c_2({\bf \vec{u}} +{\bf \vec{x}}t)={\bf 0} 
				\end {equation}
				
				By differentiating this with respect to \(t\), we see that \(c_2{\bf \vec{x}}={\bf 0}\), which implies \(c_2=0\), because \({\bf \vec{x}}\ne {\bf 0}\). Substituting \(c_2=0\) into <a href="#x1-8r5">(10.5.5)</a> yields \(c_1{\bf \vec{x}}={\bf 0}\), which implies that \(c_1=0\), again because \({\bf \vec{x}}\ne {\bf 0}\)
			</div>

			<div class="example" id="x1-92" style="--ex-number: 2">
				<div>
					Use Theorem&nbsp;<a href="#x1-41">10.5.1</a> to find the general solution of the system 
					<a id="x1-10r6"></a>
					\begin {equation} 
						\label {eq:10.5.6} 
						\dfrac{d{\bf \vec{y}}}{dt}=\twobytwo {11}{-25}4{-9}{\bf \vec{y}} 
					\end {equation}
					
					considered in Example&nbsp;<a href="#x1-21">10.5.1</a>.
				</div>

				<details class="solution">
					<summary>Solution</summary>
					<ol>
						<li class="no-part">
							In Example&nbsp;<a href="#x1-21">10.5.1</a> we saw that \(\lambda _1=1\) is an eigenvalue of multiplicity \(2\) of the coefficient matrix \(A\) in <a href="#x1-10r6">(10.5.6)</a>, and that all of the eigenvectors of \(A\) are multiples of 
							\[ {\bf \vec{x}}=\twocol 52\] 
							
							Therefore 
							\[ {\bf \vec{y}}_1=\twocol 52e^t \] 
							
							is a solution of <a href="#x1-10r6">(10.5.6)</a>. From Theorem&nbsp;<a href="#x1-41">10.5.1</a>, a second solution is given by \({\bf \vec{y}}_2={\bf \vec{u}}e^t+{\bf \vec{x}}te^t\), where \((A-I){\bf \vec{u}}={\bf \vec{x}}\). The augmented matrix of this system is 
							\[ \left [
								\begin {array}{rrcr}
									10&amp;-25&amp;\vdots&amp; 5\\
									4&amp;-10&amp;\vdots&amp; 2
								\end {array}
							\right ]\] 
							
							which is row equivalent to 
							\[ \displaystyle {\left [ 
								\begin {array}{rrcr}
									1&amp;-{5\over 2}&amp;\vdots&amp; 1\over 2\\
									0&amp;0&amp;\vdots&amp; 0 
								\end {array}
							\right ]} \] 
						</li>
						<li class="no-part">
							Therefore the components of \(\bf u\) must satisfy 
							\[ u_1-{5\over 2}u_2={1\over 2}\] 
							
							where \(u_2\) is arbitrary. We choose \(u_2=0\), so that \(u_1=1/2\) and 
							\[ {\bf \vec{u}}=\twocol {1\over 2}0\] 
							
							Thus, 
							\[ {\bf \vec{y}}_2=\twocol 10{e^t\over 2}+\twocol 52te^t\] 
							
							Since \({\bf \vec{y}}_1\) and \({\bf \vec{y}}_2\) are linearly independent by Theorem&nbsp;<a href="#x1-41">10.5.1</a>, they form a fundamental set of solutions of <a href="#x1-10r6">(10.5.6)</a>. Therefore the general solution of <a href="#x1-10r6">(10.5.6)</a> is 
							\[ {\bf \vec{y}}=c_1\twocol 52e^t+c_2\left (\twocol 10{e^t\over 2}+\twocol 52te^t\right )\]

							<div>
								Note that choosing the arbitrary constant \(u_2\) to be nonzero is equivalent to adding a scalar multiple of \({\bf \vec{y}}_1\) to the second solution \({\bf \vec{y}}_2\) (Exercise&nbsp;<span class="ptmb8t-">33</span>). 
							</div>
						</li>
					</ol>
				</details>
			</div>

			<div class="example" id="x1-112" style="--ex-number: 3">
				<div>
					Find the general solution of 
					<a id="x1-12r7"></a>
					\begin {equation} 
						\label {eq:10.5.7} 
						\dfrac{d{\bf \vec{y}}}{dt}=\threebythree 34{-10}21{-2}22{-5} {\bf \vec{y}} 
					\end {equation}
				</div>

				<details class="solution">
					<summary>Solution</summary>
					<ol>
						<li class="no-part">
							The characteristic polynomial of the coefficient matrix \(A\) in <a href="#x1-12r7">(10.5.7)</a> is 
							\[ \left | 
								\begin {array}{ccc}
									3-\lambda &amp; 4 &amp; -10\\
									2 &amp; 1-\lambda &amp; -2\\ 
									2 &amp; 2 &amp;-5-\lambda 
								\end {array}
							\right | =- (\lambda -1)(\lambda +1)^2 \]
							
							Hence, the eigenvalues are \(\lambda _1=1\) with multiplicity&nbsp;\(1\) and \(\lambda _2=-1\) with multiplicity&nbsp;\(2\).

							<div>
								Eigenvectors associated with \(\lambda _1=1\) must satisfy \((A-I){\bf \vec{x}}={\bf 0}\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										2 &amp; 4 &amp; -10 &amp;\vdots &amp; 0\\ 
										2&amp; 0 &amp; -2 &amp;\vdots &amp; 0\\ 
										2 &amp; 2 &amp; -6 &amp; \vdots &amp; 0
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 0 &amp; -1 &amp;\vdots&amp; 0\\ 
										0 &amp; 1 &amp; -2 &amp;\vdots&amp; 0\\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ]\] 
								
								Hence, \(x_1 =x_3\) and \(x_2 =2 x_3\), where \(x_3\) is arbitrary. Choosing \(x_3=1\) yields the eigenvector 
								\[ {\bf \vec{x}}_1=\threecol 121\] 
								
								Therefore 
								\[ {\bf \vec{y}}_1 =\threecol 121e^t \] 
								
								is a solution of <a href="#x1-12r7">(10.5.7)</a>.
							</div>
						</li>
						<li class="no-part">
							<div>
								Eigenvectors associated with \(\lambda _2 =-1\) satisfy \((A+I){\bf \vec{x}}={\bf 0}\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										4 &amp; 4 &amp; -10 &amp;\vdots &amp; 0\\ 
										2 &amp; 2 &amp; -2 &amp; \vdots &amp; 0\\
										2 &amp; 2 &amp; -4 &amp;\vdots &amp; 0 
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 1 &amp; 0 &amp;\vdots&amp; 0\\ 
										0 &amp; 0 &amp; 1 &amp;\vdots&amp; 0 \\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ]\] 
								
								Hence, \(x_3=0\) and \(x_1 =-x_2\), where \(x_2\) is arbitrary. Choosing \(x_2=1\) yields the eigenvector 
								\[ {\bf \vec{x}}_2=\threecol {-1}10\] 
								
								so 
								\[ {\bf \vec{y}}_2 =\threecol {-1}10e^{-t} \] 
								
								is a solution of <a href="#x1-12r7">(10.5.7)</a>.
							</div>
							<div>
								
								Since all the eigenvectors of \(A\) associated with \(\lambda _2=-1\) are multiples of \({\bf \vec{x}}_2\), we must now use Theorem&nbsp;<a href="#x1-41">10.5.1</a> to find a third solution of <a href="#x1-12r7">(10.5.7)</a> in the form 
								
								<a id="x1-13r8"></a>
								\begin {equation} 
									\label {eq:10.5.8} 
									{\bf \vec{y}}_3={\bf \vec{u}}e^{-t}+\threecol {-1}10te^{-t} 
								\end {equation}
								
								where \(\bf u\) is a solution of \((A+I){\bf u=x}_2\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										4 &amp; 4 &amp; -10 &amp;\vdots &amp; -1\\
										2 &amp; 2 &amp; -2 &amp; \vdots &amp; 1\\ 
										2 &amp; 2 &amp; -4 &amp;\vdots &amp; 0 
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 1 &amp; 0 &amp;\vdots&amp; 1\\ 
										0 &amp; 0 &amp; 1 &amp;\vdots&amp; {1\over 2} \\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ]\] 
							</div>
						</li>
						<li class="no-part">
							<div>
								Hence, \(u_3=1/2\) and \(u_1 =1-u_2\), where \(u_2\) is arbitrary. Choosing \(u_2=0\) yields 
								\[ {\bf \vec{u}} =\threecol 10{1\over 2}\] 
								
								and substituting this into <a href="#x1-13r8">(10.5.8)</a> yields the solution 
								\[ {\bf \vec{y}}_3=\threecol 201{e^{-t}\over 2}+\threecol {-1}10te^{-t} \] 
								
								of <a href="#x1-12r7">(10.5.7)</a>.
							</div>
							<div>
								Since the Wronskian of \(\{{\bf \vec{y}}_1,{\bf \vec{y}}_2,{\bf \vec{y}}_3\}\) at \(t=0\) is 
								\[ \left | 
									\begin {array}{rrr}
										1&amp;-1&amp;1\\
										2&amp;1&amp;0\\
										1&amp;0&amp;1\over 2 
									\end {array}
								\right |={1\over 2} \] 
								
								\(\{{\bf \vec{y}}_1,{\bf \vec{y}}_2,{\bf \vec{y}}_3\}\) is a fundamental set of solutions of <a href="#x1-12r7">(10.5.7)</a>. Therefore the general solution of <a href="#x1-12r7">(10.5.7)</a> is 
								\[ {\bf \vec{y}}=c_1\threecol 121e^t+c_2\threecol {-1}10e^{-t}+c_3\left (\threecol 201{e^{-t}\over 2}+\threecol {-1}10te^{-t}\right )\]
							</div>
						</li>
					</ol>
				</details>
			</div>

			<div class="theorem" id="x1-142">
				<span class="head">Theorem&nbsp;10.5.2</span>
				Suppose the \(n\times n\) matrix \(A\) has an eigenvalue \(\lambda _1\) of multiplicity \(\ge 3\) and the associated eigenspace is one–dimensional; that is, all eigenvectors associated with \(\lambda _1\) are scalar multiples of the eigenvector \({\bf \vec{x}}.\) Then there are infinitely many vectors \(\bf u\) such that 
					
				<a id="x1-15r9"></a>
				\begin {equation} 
					\label {eq:10.5.9} 
					(A-\lambda _1I){\bf \vec{u}}={\bf \vec{x}} 
				\end {equation} 
				
				and, if \(\bf u\) is any such vector, there are infinitely many vectors \(\bf v\) such that 
				
				<a id="x1-16r10"></a>
				\begin {equation} 
					\label {eq:10.5.10} 
					(A-\lambda _1I){\bf \vec{v}}={\bf \vec{u}} 
				\end {equation}
				
				If \(\bf u\) satisfies <a href="#x1-15r9">(10.5.9)</a> and \(\bf v\) satisfies <a href="#x1-16r10">(10.5.10)</a>, then
			
				<div class="eqnarray">
					\begin {eqnarray*}
						{\bf \vec{y}}_1 &amp;=&amp;{\bf \vec{x}} e^{\lambda _1t},\\ 
						{\bf \vec{y}}_2&amp;=&amp;{\bf \vec{u}}e^{\lambda _1t}+{\bf \vec{x}} te^{\lambda _1t},\mbox { and }\\ 
						{\bf \vec{y}}_3&amp;=&amp;{\bf \vec{v}}e^{\lambda _1t}+{\bf \vec{u}}te^{\lambda _1t}+{\bf \vec{x}} {t^2e^{\lambda _1t}\over 2} 
					\end {eqnarray*} 
				</div>

				are linearly independent solutions of \(\dfrac{d{\bf \vec{y}}}{dt}=A{\bf \vec{y}}\). 
			</div>

			<div id="583f90a2-820b-4e69-ac03-d021c666a43f">
				Again, it’s beyond the scope of this book to prove that there are vectors \(\bf u\) and \(\bf v\) that satisfy <a href="#x1-15r9">(10.5.9)</a> and <a href="#x1-16r10">(10.5.10)</a>. Theorem&nbsp;<a href="#x1-41">10.5.1</a> implies that \({\bf \vec{y}}_1\) and \({\bf \vec{y}}_2\) are solutions of \(\dfrac{d{\bf \vec{y}}}{dt}=A{\bf \vec{y}}\). We leave the rest of the proof to you (Exercise&nbsp;<span class="ptmb8t-">34</span>).
			</div>

			<div class="example" id="x1-174" style="--ex-number: 4">
				<div>
					Use Theorem&nbsp;<a href="#x1-142">10.5.2</a> to find the general solution of 
					<a id="x1-18r11"></a>
					\begin {equation} 
						\label {eq:10.5.11} 
						\dfrac{d{\bf \vec{y}}}{dt}=\threebythree 11113{-1}022{\bf \vec{y}} 
					\end {equation}
				</div>
			
				<details class="solution">
					<summary>Solution</summary>
					<ol>
						<li class="no-part">
							<div>
								The characteristic polynomial of the coefficient matrix \(A\) in <a href="#x1-18r11">(10.5.11)</a> is 
								\[ \left | 
									\begin {array}{ccc}
										1-\lambda &amp; 1 &amp; \phantom {-}1\\ 
										1 &amp; 3-\lambda &amp; -1\\ 
										0 &amp; 2 &amp; 2-\lambda 
									\end {array}
								\right | =-(\lambda -2)^3\] 
								
								Hence, \(\lambda _1=2\) is an eigenvalue of multiplicity \(3\). The associated eigenvectors satisfy \((A-2I){\bf x=0}\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										-1 &amp; 1 &amp; 1 &amp;\vdots &amp; 0\\ 
										1&amp; 1 &amp; -1 &amp;\vdots &amp; 0\\ 
										0 &amp; 2 &amp; 0 &amp; \vdots &amp; 0 
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 0 &amp;- 1 &amp;\vdots&amp; 0\\ 
										0 &amp; 1 &amp; 0 &amp;\vdots&amp; 0 \\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ]\] 
								
								Hence, \(x_1 =x_3\) and \(x_2 = 0\), so the eigenvectors are all scalar multiples of 
								\[ {\bf \vec{x}}_1=\threecol 101\] 
								
								Therefore 
								\[ {\bf \vec{y}}_1=\threecol 101e^{2t} \] 
								
								is a solution of <a href="#x1-18r11">(10.5.11)</a>.
							</div>
						</li>
						<li class="no-part">
							<div>
								We now find a second solution of <a href="#x1-18r11">(10.5.11)</a> in the form 
								\[ {\bf \vec{y}}_2={\bf \vec{u}}e^{2t}+\threecol 101te^{2t}\] 
								
								where \(\bf u\) satisfies \((A-2I){\bf u=x}_1\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										-1 &amp; 1 &amp; 1 &amp;\vdots &amp; 1\\ 
										1&amp; 1 &amp; -1 &amp;\vdots &amp; 0\\ 
										0 &amp; 2 &amp; 0 &amp; \vdots &amp; 1 
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 0 &amp;- 1 &amp;\vdots&amp; -{1\over 2}\\ 
										0 &amp; 1 &amp; 0 &amp;\vdots&amp; {1\over 2}\\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ]\] 
								
								Letting \(u_3=0\) yields \(u_1=-1/2\) and \(u_2=1/2\); hence, 
								\[ {\bf \vec{u}}={1\over 2}\threecol {-1}10 \] 
								
								and 
								\[ {\bf \vec{y}}_2=\threecol {-1}10{e^{2t}\over 2}+\threecol 101te^{2t} \] 
								
								is a solution of <a href="#x1-18r11">(10.5.11)</a>.
							</div>
						</li>
						<li class="no-part">
							<div>
								We now find a third solution of <a href="#x1-18r11">(10.5.11)</a> in the form 
								\[ {\bf \vec{y}}_3={\bf \vec{v}}e^{2t}+\threecol {-1}10{te^{2t}\over 2}+\threecol 101{t^2e^{2t}\over 2} \] 
								
								where \(\bf v\) satisfies \((A-2I){\bf \vec{v}}={\bf \vec{u}}\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										-1 &amp; 1 &amp; 1 &amp;\vdots &amp;-{1\over 2}\\ 
										1&amp; 1 &amp; -1 &amp;\vdots &amp; {1\over 2}\\ 
										0 &amp; 2 &amp; 0 &amp; \vdots &amp; 0 
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 0 &amp;- 1 &amp;\vdots&amp; {1\over 2}\\ 
										0 &amp; 1 &amp; 0 &amp;\vdots&amp; 0\\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ]\] 
								
								Letting \(v_3=0\) yields \(v_1=1/2\) and \(v_2=0\); hence, 
								\[ {\bf \vec{v}}={1\over 2}\threecol 100\] 
								
								Therefore 
								\[ {\bf \vec{y}}_3=\threecol 100{e^{2t}\over 2}+ \threecol {-1}10{te^{2t}\over 2}+\threecol 101{t^2e^{2t}\over 2} \] 
								
								is a solution of <a href="#x1-18r11">(10.5.11)</a>. Since \({\bf \vec{y}}_1\), \({\bf \vec{y}}_2\), and \({\bf \vec{y}}_3\) are linearly independent by Theorem&nbsp;<a href="#x1-142">10.5.2</a>, they form a fundamental set of solutions of <a href="#x1-18r11">(10.5.11)</a>. Therefore the general solution of <a href="#x1-18r11">(10.5.11)</a> is
								<div class="eqnarray">
									\begin {eqnarray*}
										{\bf \vec{y}} &amp;=&amp;\displaystyle {c_1\threecol 101e^{2t}+ c_2\left (\threecol {-1}10{e^{2t}\over 2}+\threecol 101te^{2t}\right )}\\
										&amp;&amp;+c_3\displaystyle {\left (\threecol 100{e^{2t}\over 2}+ \threecol {-1}10{te^{2t}\over 2}+\threecol 101{t^2e^{2t}\over 2}\right )} 
									\end {eqnarray*} 
								</div>
							</div>
						</li>
					</ol>
				</details>
			</div>

			<div class="theorem" id="x1-193">
				<span class="head">Theorem&nbsp;10.5.3</span>
				Suppose the \(n\times n\) matrix \(A\) has an eigenvalue \(\lambda _1\) of multiplicity \(\ge 3\) and the associated eigenspace is two–dimensional; that is, all eigenvectors of \(A\) associated with \(\lambda _1\) are linear combinations of two linearly independent eigenvectors \({\bf \vec{x}}_1\) and \({\bf \vec{x}}_2\)\(.\) Then there are constants \(\alpha \) and \(\beta \) \((\)not both zero\()\) such that if 
				
				<a id="x1-20r12"></a>
				\begin {equation} 
					\label {eq:10.5.12} 
					{\bf \vec{x}}_3=\alpha {\bf \vec{x}}_1+\beta {\bf \vec{x}}_2 
				\end {equation}
				
				then there are infinitely many vectors \(\bf u\) such that 
				
				<a id="x1-21r13"></a>
				\begin {equation} 
					\label {eq:10.5.13} 
					(A-\lambda _1I){\bf \vec{u}}={\bf \vec{x}}_3 
				\end {equation}
				
				If \(\bf u\) satisfies <a href="#x1-21r13">(10.5.13)</a>, then
			
				<div class="eqnarray">
					\begin {eqnarray} 
						{\bf \vec{y}}_1&amp;=&amp;{\bf \vec{x}}_1 e^{\lambda _1t},\nonumber \\ 
						{\bf \vec{y}}_2&amp;=&amp;{\bf \vec{x}}_2e^{\lambda _1t},\mbox {and }\nonumber \\ 
						{\bf \vec{y}}_3&amp;=&amp;{\bf \vec{u}}e^{\lambda _1t}+{\bf \vec{x}}_3te^{\lambda _1t}
						\label {eq:10.5.14} 
					\end {eqnarray} 
				</div>

				are linearly independent solutions of \(\dfrac{d{\bf \vec{y}}}{dt}=A{\bf \vec{y}}.\) 
			</div>

			<div id="0e77b935-a80d-4a5b-96e2-04a5118509fe">
				We omit the proof of this theorem. 
			</div>

			<div class="example" id="x1-225" style="--ex-number: 5">
				<div>
					Use Theorem&nbsp;<a href="#x1-193">10.5.3</a> to find the general solution of 
					<a id="x1-23r14"></a>
					\begin {equation} 
						\label {eq:10.5.15} 
						\dfrac{d{\bf \vec{y}}}{dt}=\threebythree 001{-1}11{-1}02{\bf \vec{y}} 
					\end {equation}
				</div>

				<details class="solution">
					<summary>Solution</summary>
					<ol>
						<li class="no-part">
							<div>
								The characteristic polynomial of the coefficient matrix \(A\) in <a href="#x1-23r14">(10.5.15)</a> is 
								\[ \left | 
									\begin {array}{ccc}
										-\lambda &amp; 0 &amp; 1\\ 
										-1 &amp; 1-\lambda &amp; 1\\ 
										-1 &amp; 0 &amp; 2-\lambda 
									\end {array}
								\right | =-(\lambda -1)^3\] 
								
								Hence, \(\lambda _1=1\) is an eigenvalue of multiplicity \(3\). The associated eigenvectors satisfy \((A-I){\bf x=0}\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										-1 &amp; 0 &amp; 1 &amp;\vdots &amp; 0\\ 
										-1&amp; 0 &amp; 1 &amp;\vdots &amp; 0\\ 
										-1 &amp; 0 &amp; 1 &amp; \vdots &amp; 0 
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 0 &amp;- 1 &amp;\vdots&amp; 0\\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 \\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ]\] 
								
								Hence, \(x_1 =x_3\) and \(x_2\) is arbitrary, so the eigenvectors are of the form 
								\[ {\bf \vec{x}}_1=\threecol {x_3}{x_2}{x_3}=x_3\threecol 101+x_2\threecol 010\] 
								
								Therefore the vectors 
								
								<a id="x1-24r15"></a>
								\begin {equation} 
									\label {eq:10.5.16} 
									{\bf \vec{x}}_1 =\threecol 101\quad \mbox {and }\quad {\bf \vec{x}}_2=\threecol 010 
								\end {equation}
								
								form a basis for the eigenspace, and 
								\[ {\bf \vec{y}}_1 =\threecol 101e^t\quad \mbox {and }\quad {\bf \vec{y}}_2=\threecol 010e^t \] 
								
								are linearly independent solutions of <a href="#x1-23r14">(10.5.15)</a>.
							</div>
						</li>
						<li class="no-part">
							<div>
								To find a third linearly independent solution of <a href="#x1-23r14">(10.5.15)</a>, we must find constants \(\alpha \) and \(\beta \) (not both zero) such that the system 
								<a id="x1-25r16"></a>
								\begin {equation} 
									\label {eq:10.5.17} 
									(A-I){\bf \vec{u}}=\alpha {\bf \vec{x}}_1+\beta {\bf \vec{x}}_2 
								\end {equation}
								
								has a solution \(\bf u\). The augmented matrix of this system is 
								\[ \left [ 
									\begin {array}{rrrcr}
										-1 &amp; 0 &amp; 1 &amp;\vdots &amp;\alpha \\ 
										-1&amp; 0 &amp; 1 &amp;\vdots &amp;\beta \\ 
										-1 &amp; 0 &amp; 1 &amp; \vdots &amp;\alpha 
									\end {array}
								\right ]\] 
								
								which is row equivalent to 
								
								<a id="x1-26r17"></a>
								\begin {equation} 
									\label {eq:10.5.18} 
									\left [ 
										\begin {array}{rrrcr}
											1 &amp; 0 &amp;- 1 &amp;\vdots &amp; -\alpha \\ 
											0 &amp; 0 &amp; 0 &amp;\vdots &amp;\beta -\alpha \\ 
											0 &amp; 0 &amp; 0 &amp;\vdots &amp;0 
										\end {array}
									\right ]
								\end {equation}
								
								Therefore <a href="#x1-25r16">(10.5.17)</a> has a solution if and only if \(\beta =\alpha \), where \(\alpha \) is arbitrary. If \(\alpha =\beta =1\) then <a href="#x1-20r12">(10.5.12)</a> and <a href="#x1-24r15">(10.5.16)</a> yield 
								\[ {\bf \vec{x}}_3={\bf \vec{x}}_1+{\bf \vec{x}}_2= \threecol 101+\threecol 010=\threecol 111\] 
								
								and the augmented matrix <a href="#x1-26r17">(10.5.18)</a> becomes 
								\[ \left [ 
									\begin {array}{rrrcr}
										1 &amp; 0 &amp;- 1 &amp;\vdots&amp; -1\\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0\\ 
										0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 
									\end {array}
								\right ] \]
								
								This implies that \(u_1=-1+u_3\), while \(u_2\) and \(u_3\) are arbitrary. Choosing \(u_2=u_3=0\) yields 
								\[ {\bf \vec{u}}=\threecol {-1}00\] 
								
								Therefore (<span class="ptmb8t-">10.5.14</span>) implies that 
								\[ {\bf \vec{y}}_3={\bf \vec{u}}e^t+{\bf \vec{x}}_3te^t=\threecol {-1}00e^t+\threecol 111te^t \] 
								
								is a solution of <a href="#x1-23r14">(10.5.15)</a>. Since \({\bf \vec{y}}_1\), \({\bf \vec{y}}_2\), and \({\bf \vec{y}}_3\) are linearly independent by Theorem&nbsp;<a href="#x1-193">10.5.3</a>, they form a fundamental set of solutions for <a href="#x1-23r14">(10.5.15)</a>. Therefore the general solution of <a href="#x1-23r14">(10.5.15)</a> is 
								\[ {\bf \vec{y}}=c_1\threecol 101e^t+c_2\threecol 010e^t +c_3\left (\threecol {-1}00e^t+\threecol 111te^t\right )\]
							
							</div>
						</li>
					</ol>
				</details>
			</div>

			<div class="example" id="x1-101" style="--ex-number: 6">
				<a id="x1-1615"></a>
				\(\displaystyle {\dfrac{d{\bf \vec{y}}}{dt}= \threebythree {-5}{-1}{11}{-7}1{13}{-4}08{\bf \vec{y}},\quad {\bf \vec{y}}(0)=\threecol 022}\) 
			</div>
		</details>
		
		<details class="removed" id="ef5d1188-eb27-4fdf-a437-e65d53b6d0ab">
			<summary>Geometric Properties of Solutions when \(n=2\)</summary>

			<div id="f4ad3e08-7ca5-4d6b-b631-a71d4c46bceb">
				We’ll now consider the geometric properties of solutions of a \(2\times 2\) constant coefficient system 
				<a id="x1-27r18"></a>
				\begin {equation} 
					\label {eq:10.5.19} 
					\twocol {\dfrac{dy_1}{dt}}{\dfrac{dy_2}{dt}}=\left [ 
						\begin {array}{cc}
							a_{11}&amp;a_{12}\\
							a_{21}&amp;a_{22} 
						\end {array}
					\right ]\twocol {y_1}{y_2} 
				\end {equation}
				
				under the assumptions of this section; that is, when the matrix 
				\[ A=\left [
					\begin {array}{cc}
						a_{11}&amp;a_{12}\\
						a_{21}&amp;a_{22} 
					\end {array}
				\right ] \] 
				
				has a repeated eigenvalue \(\lambda _1\) and the associated eigenspace is one-dimensional. In this case we know from Theorem&nbsp;<a href="#x1-41">10.5.1</a> that the general solution of <a href="#x1-27r18">(10.5.19)</a> is 
				<a id="x1-28r19"></a>
				\begin {equation} 
					\label {eq:10.5.20} 
					{\bf \vec{y}}=c_1{\bf \vec{x}}e^{\lambda _1t}+c_2({\bf \vec{u}}e^{\lambda _1t}+{\bf \vec{x}}te^{\lambda _1t}) 
				\end {equation}
				
				where \(\bf x\) is an eigenvector of \(A\) and \(\bf u\) is any one of the infinitely many solutions of 
				<a id="x1-29r20"></a>
				\begin {equation} 
					\label {eq:10.5.21} 
					(A-\lambda _1I){\bf \vec{u}}={\bf \vec{x}} 
				\end {equation}
				
				We assume that \(\lambda _1\ne 0\).
			
			</div>

			<figure id="x1-30r1">
				<img height="264" src="EPS/fig100501.png" />
				<figcaption>
					<span class="id">Figure&nbsp;10.5.1</span>
					<span class="content">Positive and negative half-planes</span>
				</figcaption>
			</figure>

			<div id="7c9f4988-6c87-4480-90a9-f2e2cc357091">
				Let \(L\) denote the line through the origin parallel to \(\bf x\). By a<span class="vocab">half-line</span>of \(L\) we mean either of the rays obtained by removing the origin from \(L\). Eqn.&nbsp;<a href="#x1-28r19">(10.5.20)</a> is a parametric equation of the half-line of \(L\) in the direction of \(\bf x\) if \(c_1&gt;0\), or of the half-line of \(L\) in the direction of \(-{\bf \vec{x}}\) if \(c_1&lt;0\). The origin is the trajectory of the trivial solution \({\bf \vec{y}}\equiv {\bf 0}\).
			</div>
			<div id="b0049e05-89df-4a91-a360-d99fdad08439">
				Henceforth, we assume that \(c_2\ne 0\). In this case, the trajectory of <a href="#x1-28r19">(10.5.20)</a> can’t intersect \(L\), since every point of \(L\) is on a trajectory obtained by setting \(c_2=0\). Therefore the trajectory of <a href="#x1-28r19">(10.5.20)</a> must lie entirely in one of the open half-planes bounded by \(L\), but does not contain any point on \(L\). Since the initial point \((y_1(0),y_2(0))\) defined by \({\bf \vec{y}}(0)=c_1{\bf \vec{x}}_1+c_2{\bf \vec{u}}\) is on the trajectory, we can determine which half-plane contains the trajectory from the sign of \(c_2\), as shown in Figure&nbsp;<a href="#x1-30r1">10.5.1</a>. For convenience we’ll call the half-plane where \(c_2&gt;0\) the<span class="vocab">positive half-plane</span>. Similarly, the-half plane where \(c_2&lt;0\) is the<span class="vocab">negative half-plane</span>. You should convince yourself (Exercise&nbsp;<span class="ptmb8t-">35</span>) that even though there are infinitely many vectors \(\bf u\) that satisfy <a href="#x1-29r20">(10.5.21)</a>, they all define the same positive and negative half-planes. In the figures simply regard \(\bf u\) as an arrow pointing to the positive half-plane, since wen’t attempted to give \(\bf u\) its proper length or direction in comparison with \(\bf x\). For our purposes here, only the relative orientation of \(\bf x\) and \(\bf u\) is important; that is, whether the positive half-plane is to the right of an observer facing the direction of \(\bf x\) (as in Figures&nbsp;<a href="#x1-33r2">10.5.2</a> and <a href="#x1-36r5">10.5.5</a>), or to the left of the observer (as in Figures&nbsp;<a href="#x1-34r3">10.5.3</a> and <a href="#x1-35r4">10.5.4</a>).
			</div>
			<div id="bfd9ae01-6e16-4ba0-b2a9-ce6183c9f27b">
				Multiplying <a href="#x1-28r19">(10.5.20)</a> by \(e^{-\lambda _1t}\) yields 
				\[ e^{-\lambda _1t}{\bf \vec{y}}(t)=c_1{\bf \vec{x}}+c_2{\bf \vec{u}}+c_2t {\bf \vec{x}}\] 
			
				Since the last term on the right is dominant when \(|t|\) is large, this provides the following information on the direction of \({\bf \vec{y}}(t)\):
			</div>
			<div class="stepbox" id="508dfe64-05de-4c47-b4d0-676c5cbe9c92">
				<ol style="list-style: lower-roman">
					<li>
						Along trajectories in the positive half-plane (\(c_2&gt;0\)), the direction of \({\bf \vec{y}}(t)\) approaches the direction of \(\bf x\) as \(t\to \infty \) and the direction of \(-{\bf \vec{x}}\) as \(t\to -\infty \). 
					</li>
					<li>
						Along trajectories in the negative half-plane (\(c_2&lt;0\)), the direction of \({\bf \vec{y}}(t)\) approaches the direction of \(-{\bf \vec{x}}\) as \(t\to \infty \) and the direction of \(\bf x\) as \(t\to -\infty \). 
					</li>
				</ol>
			</div>

			<div id="85b1a7c4-89d1-437b-90bd-254332255999">
				Since 
				\[ \lim _{t\to \infty }\|{\bf \vec{y}}(t)\|=\infty \quad \mbox{ and } \quad \lim _{t\to -\infty }{\bf \vec{y}}(t)={\bf 0}\quad \mbox{ if } \quad \lambda _1&gt;0\] 
				
				or 
				\[ \lim _{t-\to \infty }\|{\bf \vec{y}}(t)\|=\infty \quad \mbox{ and } \quad \lim _{t\to \infty }{\bf \vec{y}}(t)={\bf 0}\quad \mbox{ if } \quad \lambda _1&lt;0\] 
				
				there are four possible patterns for the trajectories of <a href="#x1-27r18">(10.5.19)</a>, depending upon the signs of \(c_2\) and \(\lambda _1\). Figures&nbsp;<a href="#x1-33r2">10.5.2</a>-<a href="#x1-36r5">10.5.5</a> illustrate these patterns, and reveal the following principle:
			</div>
			<div id="5305bb2c-1096-46c9-9791-e02ac87628c2">
				If \(\lambda _1\) and \(c_2\) have the same sign then the direction of the trajectory approaches the direction of \(-{\bf \vec{x}}\) as \(\|{\bf \vec{y}} \|\to 0\) and the direction of \(\bf x\) as \(\|{\bf \vec{y}}\|\to \infty \). If \(\lambda _1\) and \(c_2\) have opposite signs then the direction of the trajectory approaches the direction of \(\bf x\) as \(\|{\bf \vec{y}} \|\to 0\) and the direction of \(-{\bf \vec{x}}\) as \(\|{\bf \vec{y}}\|\to \infty \). 
			</div>

			<figure id="x1-33r2">
				<img height="264" src="EPS/fig100502.png" />
				<figcaption>
					<span class="id">Figure&nbsp;10.5.2</span>
					<span class="content">Positive eigenvalue; motion away from the origin</span>
				</figcaption>
			</figure>

			<figure id="x1-34r3">
				<img height="264" src="EPS/fig100503.png" />
				<figcaption>
					<span class="id">Figure&nbsp;10.5.3</span>
					<span class="content">Positive eigenvalue; motion away from the origin</span>
				</figcaption>
			</figure>

			<figure id="x1-35r4">
				<img height="264" src="EPS/fig100504.png" />
				<figcaption>
					<span class="id">Figure&nbsp;10.5.4</span>
					<span class="content">Negative eigenvalue; motion toward the origin</span>
				</figcaption>
			</figure>

			<figure id="x1-36r5">
				<img height="264" src="EPS/fig100505.png" />
				<figcaption>
					<span class="id">Figure&nbsp;10.5.5</span>
					<span class="content">Negative eigenvalue; motion toward the origin</span>
				</figcaption>
			</figure>
		</details>

		<nav class="ex">
			<a href="sec10.5.ex.html">10.5 Exercises</a>
		</nav>

		<nav class="book">
			<a href="sec10.4.book.html">Back (10.4)</a>

			<a href="sec10.0.html">Chapter 10</a>

			<a href="sec10.6.book.html">Next (10.6)</a>
		</nav>
	</body>
</html>
