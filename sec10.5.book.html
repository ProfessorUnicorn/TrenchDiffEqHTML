<!DOCTYPE html><html lang="en-US" xml:lang="en-US"><head>
  <title></title>
  <meta charset="utf-8">
  <meta content="TeX4ht (https://tug.org/tex4ht/)" name="generator">
  <meta content="width=device-width,initial-scale=1" name="viewport">
  <link rel="stylesheet" type="text/css" href="combined.css">
  <meta content="Trench_DiffEQ_Book.tex" name="src">
  <script>window.MathJax = {
      tex: { packages: { '[+]': ['tagformat'] }, tags: "ams", tagformat: { tag: (tag) => '(10.5.' + tag + ')' } }
    }; </script>
  <script async="async" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <style type="text/css">
    :root {
      --section-number: "10.5"
    }
  </style>
</head>

<body>
  <div style="display: none;" id="920b6727-0fdb-4653-8ab5-4270cc72aeb7">
    \(
    \newcommand{\place}{\bigskip\hrule\bigskip\noindent}
    \newcommand{\threecol}[3]{\left[\begin{array}{r}#1\\#2\\#3\end{array}\right]}
    \newcommand{\threecolj}[3]{\left[\begin{array}{r}#1\\#2\\#3\end{array}\right]}
    \newcommand{\lims}[2]{\,\bigg|_{#1}^{#2}}
    \newcommand{\twocol}[2]{\left[\begin{array}{l}#1\\#2\end{array}\right]}
    \newcommand{\ctwocol}[2]{\left[\begin{array}{c}#1\\#2\end{array}\right]}
    \newcommand{\cthreecol}[3]{\left[\begin{array}{c}#1\\#2\\#3\end{array}\right]}
    \newcommand{\eqline}[1]{\centerline{\hfill$\displaystyle#1$\hfill}}
    \newcommand{\twochar}[4]{\left|\begin{array}{cc}
    #1-\lambda&amp; #2\\#3&amp; #4-\lambda\end{array}\right|}
    \newcommand{\twobytwo}[4]{\left[\begin{array}{rr}
    #1&amp; #2\\#3&amp; #4\end{array}\right]}
    \newcommand{\threechar}[9]{\left[\begin{array}{ccc}
    #1-\lambda&amp; #2&amp; #3\\#4&amp; #5-\lambda&amp; #6\\#7&amp; #8&amp; #9-\lambda\end{array}\right]}
    \newcommand{\threebythree}[9]{\left[\begin{array}{rrr}
    #1&amp; #2&amp; #3\\#4&amp; #5&amp; #6\\#7&amp; #8&amp; #9\end{array}\right]}
    \newcommand{\solutionpart}[1]{\vskip10pt\noindent\underbar{\color{blue}\sc
    Solution({\bf #1})\ }}
    \newcommand{\Cex}{\fbox{\textcolor{red}{C}}\, }
    \newcommand{\CGex}{\fbox{\textcolor{red}{C/G}}\, }
    \newcommand{\Lex}{\fbox{\textcolor{red}{L}}\, }

    \newcommand{\matfunc}[3]{\left[\begin{array}{cccc}#1_{11}(t)&amp; #1_{12}(t)&amp;\cdots
    &amp; #1_{1#3}(t)\\#1_{21}(t)&amp; #1_{22}(t)&amp;\cdots&amp; #1_{2#3}(t)\\\vdots&amp;
    \vdots&amp;\ddots&amp;\vdots\\#1_{#21}(t)&amp; #1_{#22}(t)&amp;\cdots&amp; #1_{#2#3}(t)
    \end{array}\right]}


    \newcommand{\col}[2]{\left[\begin{array}{c}#1_1\\#1_2\\\vdots\\#1_#2\end{array}\right]}
    \newcommand{\colfunc}[2]{\left[\begin{array}{c}#1_1(t)\\#1_2(t)\\\vdots\\#1_#2(t)\end{array}\right]}

    \newcommand{\cthreebythree}[9]{\left[\begin{array}{ccc}
    #1&amp; #2&amp; #3\\#4&amp; #5&amp; #6\\#7&amp; #8&amp; #9\end{array}\right]}

    \)
  </div>
  <div id="ed512490-3ecb-4c1c-8d1b-72d7626d5a65"><a id="x1-1doc"></a>
  </div>
  <div class="noindent" id="7c02b686-8ce9-49dc-9d68-7ffd7ef81e1b">Section 10.5 Constant Coefficient Homogeneous Systems II
  </div>
  <div class="noindent" id="1dc2243d-9b52-42a2-b98d-7ff91d8a6d2e"><span class="ptmb8t-">10.5</span><span class="ptmb8t-x-x-90">&nbsp; CONSTANT COEFFICIENT HOMOGENEOUS
      SYSTEMS II</span>
  </div>
  <div class="noindent" id="34d411f8-5671-4023-9222-26a5412ae85b">We saw in Section&nbsp;10.4 that if an \(n\times n\) constant matrix \(A\) has \(n\) real eigenvalues
    \(\lambda _1\), \(\lambda _2\), …, \(\lambda _n\) (which need not
    be distinct) with associated linearly independent eigenvectors \({\bf x}_1\), \({\bf x}_2\), …, \({\bf x}_n\), then
    the general solution of \({\bf y}'=A{\bf y}\)
    is
    \[ {\bf y}=c_1{\bf x}_1e^{\lambda _1t}+c_2{\bf x}_2e^{\lambda _2 t} +\cdots +c_n{\bf x}_ne^{\lambda _n t}\]
    In this section we consider the case where \(A\) has \(n\) real eigenvalues, but does not have \(n\) linearly
    independent
    eigenvectors. It is shown in linear algebra that this occurs if and only if \(A\) has at least one eigenvalue of
    multiplicity \(r&gt;1\) such that the associated eigenspace has dimension less than \(r\). In this case \(A\) is
    said to
    be <span class="vocab">defective</span>. Since it’s beyond the scope of this book to give a complete analysis of
    systems with
    defective coefficient matrices, we will restrict our attention to some commonly occurring special
    cases.
  </div>
  <div class="newtheorem" id="58b26352-4979-44d3-aca0-bc6c5ffbf7ad">
    <div class="noindent"><span class="head">
        <span class="ex-number">Example&nbsp;10.5.1</span> </span><a id="x1-21"></a> Show that the system \begin {equation}
      \label {eq:10.5.1} {\bf y}'=\twobytwo {11}{-25}4{-9}{\bf y} \end {equation}<a id="x1-3r1"></a> does not have a
      fundamental set of solutions of the form \(\{{\bf x}_1e^{\lambda _1t},{\bf x}_2e^{\lambda _2t}\}\), where
      \(\lambda _1\) and \(\lambda _2\)
      are eigenvalues of the coefficient matrix \(A\) of (<a href="#x1-3r1">10.5.1<!-- tex4ht:ref: eq:10.5.1  --></a>)
      and \({\bf x}_1\), and \({\bf x}_2\) are associated linearly independent
      eigenvectors.
    </div>
  </div>
  <div class="indent" id="a67e1e1c-8ae4-45ed-a66d-bacca5cd4eb1">
  </div>
  <div class="noindent" id="83b49456-b19b-4985-aa8b-4be253cd8551"><span class="ptmb8t-">Solution </span>&nbsp;The characteristic polynomial of \(A\) is </div>
  <div class="eqnarray" id="fb4bfdae-3e65-44b2-819c-e1c077cd8703">\begin {eqnarray*} \twochar {11}{-25}4{-9} &amp;=&amp;(\lambda -11)(\lambda +9)+100\\
    &amp;=&amp;\lambda ^2-2\lambda +1=(\lambda -1)^2\end {eqnarray*}</div>
  <div class="indent" id="ffb2840c-140c-43da-9f71-21d4e1e6a86b"> Hence, \(\lambda =1\) is the only eigenvalue of \(A\). The augmented matrix of the system
    \((A-I){\bf x}={\bf 0}\) is



    \[ \left [\begin {array}{rrcr}10&amp;-25&amp;\vdots&amp; 0\\4&amp; -10&amp;\vdots&amp; 0\end {array}\right ]\]
    which is row equivalent to
    \[ \left [\begin {array}{rrcr}1&amp;-\displaystyle {5\over 2}&amp;\vdots&amp; 0\\[10pt]0&amp; 0&amp;\vdots&amp;
    0\end {array}\right ]\]
    Hence, \(x_1=5x_2/2\) where \(x_2\) is arbitrary. Therefore all eigenvectors of \(A\) are scalar multiples of \({\bf
    x}_1=\displaystyle {\twocol 52}\), so \(A\) does not have a set of two
    linearly independent eigenvectors. __
  </div>
  <div class="indent" id="637fe797-850e-4555-a5ef-242d62b29dd0"> From Example&nbsp;<a href="#x1-21">10.5.1<!-- tex4ht:ref: example:10.5.1  --></a>, we know that all
    scalar multiples of \({\bf y}_1=\displaystyle {\twocol 52}e^t\) are solutions of (<a href="#x1-3r1">10.5.1<!-- tex4ht:ref: eq:10.5.1  --></a>); however, to find the
    general solution we must find a second solution \({\bf y}_2\) such that \(\{{\bf y}_1,{\bf y}_2\}\) is linearly
    independent. Based on your recollection of
    the procedure for solving a constant coefficient scalar equation
    \[ ay''+by'+cy=0 \]
    in the case where the characteristic polynomial has a repeated root, you might expect to obtain a second
    solution of (<a href="#x1-3r1">10.5.1<!-- tex4ht:ref: eq:10.5.1  --></a>) by multiplying the first solution by
    \(t\). However, this yields \({\bf y}_2=\displaystyle {\twocol 52}te^t\), which doesn’t work,
    since



    \[ {\bf y}_2'=\twocol 52(te^t+e^t),\quad \mbox{ while } \quad  \twobytwo {11}{-25}4{-9}{\bf y}_2=\twocol 52te^t\]
  </div>
  <div class="indent" id="edd5997f-eedd-4b79-9e44-1c1f5a139fec"> The next theorem shows what to do in this situation.
  </div>
  <div class="newtheorem" id="7b977a68-eb8d-49d7-aee3-ba8325f6dd10">
    <div class="noindent"><span class="head">
        <span class="ptmb8t-">Theorem&nbsp;10.5.1</span> </span><a id="x1-41"></a> Suppose the
      \(n\times n\) matrix \(A\) has an eigenvalue \(\lambda
      _1\) of multiplicity \(\ge 2\) and the associated eigenspace
        has
        dimension \(1;\) that is, all \(\lambda
      _1\)-eigenvectors of \(A\) are scalar multiples of an
        eigenvector \({\bf x}.\) Then there are infinitely
        many vectors \(\bf u\) such that \begin {equation} \label {eq:10.5.2}
      (A-\lambda _1I){\bf u}={\bf x}\end {equation}<a id="x1-5r2"></a> Moreover, if \(\bf u\) is any such vector then \begin {equation}
      \label {eq:10.5.3} {\bf y}_1={\bf x}e^{\lambda _1t}\quad \mbox {and }\quad {\bf y}_2={\bf u}e^{\lambda _1t}+{\bf
      x}te^{\lambda _1t} \end {equation}<a id="x1-6r3"></a> are linearly independent solutions
      of \({\bf y}'=A{\bf y}.\)
    </div>
  </div>
  <div class="indent" id="8b5ea07f-7b84-4fb2-9086-b4d7e3aa8fc2">
  </div>
  <div class="indent" id="deb5f245-266e-424e-a605-65e4b5995579"> A complete proof of this theorem is beyond the scope of this book. The difficulty is in proving
    that there’s a
    vector \(\bf u\) satisfying (<a href="#x1-5r2">10.5.2<!-- tex4ht:ref: eq:10.5.2  --></a>), since \(\det (A-\lambda
    _1I)=0\). We’ll take this without proof and verify the other assertions of the
    theorem.
  </div>
  <div class="indent" id="5771adba-8ada-486b-a623-7bbca4f512e4"> We already know that \({\bf y}_1\) in (<a href="#x1-6r3">10.5.3<!-- tex4ht:ref: eq:10.5.3  --></a>)
    is a solution of \({\bf y}'=A{\bf y}\). To see that \({\bf y}_2\) is also a solution, we compute
  </div>
  <div class="eqnarray" id="fd388160-95c2-47ae-9eef-d588b56ab51c">\begin {eqnarray*} {\bf y}_2'-A{\bf y}_2&amp;=&amp;\lambda _1{\bf u}e^{\lambda _1t}+{\bf x}
    e^{\lambda _1t} +\lambda _1{\bf x} te^{\lambda _1t}-A{\bf u}e^{\lambda _1t}-A{\bf x} te^{\lambda _1t}\\
    &amp;=&amp;(\lambda _1{\bf u}+{\bf x} -A{\bf u})e^{\lambda _1t}+(\lambda _1{\bf x} -A{\bf x} )te^{\lambda _1t}\end
    {eqnarray*}</div>
  <div class="indent" id="4f66ef3b-bdd6-48c2-8742-108a991e6154"> Since \(A{\bf x}=\lambda _1{\bf x}\), this can be written as
    \[ {\bf y}_2'-A{\bf y}_2=- \left ((A-\lambda _1I){\bf u}-{\bf x}\right )e^{\lambda _1t}\]
    and now (<a href="#x1-5r2">10.5.2<!-- tex4ht:ref: eq:10.5.2  --></a>) implies that \({\bf y}_2'=A{\bf y}_2\).
  </div>
  <div class="indent" id="4267adeb-f5f5-4ffc-b28f-cdda2b70450f"> To see that \({\bf y}_1\) and \({\bf y}_2\) are linearly independent, suppose \(c_1\) and \(c_2\)
    are constants such that \begin {equation} \label {eq:10.5.4} c_1{\bf y}_1+c_2{\bf y}_2=c_1{\bf x}e^{\lambda
    _1t}+c_2({\bf u}e^{\lambda _1t} +{\bf x}te^{\lambda _1t})={\bf 0}\end {equation}<a id="x1-7r4"></a> We must show
    that \(c_1=c_2=0\).
    Multiplying (<a href="#x1-7r4">10.5.4<!-- tex4ht:ref: eq:10.5.4  --></a>) by \(e^{-\lambda _1t}\) shows that \begin
    {equation} \label {eq:10.5.5} c_1{\bf x}+c_2({\bf u} +{\bf x}t)={\bf 0}\end {equation}<a id="x1-8r5"></a> By
    differentiating this with respect to \(t\), we see that \(c_2{\bf x}={\bf 0}\), which implies \(c_2=0\), because
    \({\bf x}\ne {\bf 0}\).
    Substituting \(c_2=0\) into (<a href="#x1-8r5">10.5.5<!-- tex4ht:ref: eq:10.5.5  --></a>) yields \(c_1{\bf x}={\bf
    0}\), which implies that \(c_1=0\), again because \({\bf x}\ne {\bf 0}\)
  </div>
  <div class="newtheorem" id="473da454-19f1-46a7-b4d0-b251635bcb45">
    <div class="noindent"><span class="head">
        <span class="ex-number">Example&nbsp;10.5.2</span> </span><a id="x1-92"></a>Use Theorem&nbsp;<a href="#x1-41">10.5.1<!-- tex4ht:ref: thmtype:10.5.1  --></a> to find the general solution of the system \begin
      {equation} \label {eq:10.5.6} {\bf y}'=\twobytwo {11}{-25}4{-9}{\bf y} \end {equation}<a id="x1-10r6"></a>
      considered in
      Example&nbsp;<a href="#x1-21">10.5.1<!-- tex4ht:ref: example:10.5.1  --></a>.
    </div>
  </div>
  <div class="indent" id="16214148-3371-44dd-8007-08862f611054">



  </div>
  <div class="noindent" id="70a8db91-ce28-4278-9ce2-53ca7daabe0b"><span class="ptmb8t-">Solution </span>&nbsp;In Example&nbsp;<a href="#x1-21">10.5.1<!-- tex4ht:ref: example:10.5.1  --></a> we saw that \(\lambda _1=1\) is an eigenvalue of
    multiplicity \(2\) of the coefficient matrix \(A\) in (<a href="#x1-10r6">10.5.6<!-- tex4ht:ref: eq:10.5.6  --></a>),
    and that all of the eigenvectors of \(A\) are multiples of
    \[ {\bf x}=\twocol 52\]
    Therefore
    \[ {\bf y}_1=\twocol 52e^t \]
    is a solution of (<a href="#x1-10r6">10.5.6<!-- tex4ht:ref: eq:10.5.6  --></a>). From Theorem&nbsp;<a href="#x1-41">10.5.1<!-- tex4ht:ref: thmtype:10.5.1  --></a>, a second solution is given by \({\bf y}_2={\bf
    u}e^t+{\bf x}te^t\), where \((A-I){\bf u}={\bf x}\). The augmented matrix of
    this system is
    \[ \left [\begin {array}{rrcr}10&amp;-25&amp;\vdots&amp; 5\\4&amp;-10&amp;\vdots&amp; 2\end {array}\right ]\]
    which is row equivalent to



    \[ \displaystyle {\left [\begin {array}{rrcr}1&amp;-{5\over 2}&amp;\vdots&amp; 1\over 2\\ 0&amp;0&amp;\vdots&amp;
    0\end {array}\right ]}\]
    Therefore the components of \(\bf u\) must satisfy
    \[ u_1-{5\over 2}u_2={1\over 2}\]
    where \(u_2\) is arbitrary. We choose \(u_2=0\), so that \(u_1=1/2\) and
    \[ {\bf u}=\twocol {1\over 2}0\]
    Thus,
    \[ {\bf y}_2=\twocol 10{e^t\over 2}+\twocol 52te^t\]
    Since \({\bf y}_1\) and \({\bf y}_2\) are linearly independent by Theorem&nbsp;<a href="#x1-41">10.5.1<!-- tex4ht:ref: thmtype:10.5.1  --></a>, they form a fundamental set of solutions of (<a href="#x1-10r6">10.5.6<!-- tex4ht:ref: eq:10.5.6  --></a>).
    Therefore the general solution of (<a href="#x1-10r6">10.5.6<!-- tex4ht:ref: eq:10.5.6  --></a>) is



    \[ {\bf y}=c_1\twocol 52e^t+c_2\left (\twocol 10{e^t\over 2}+\twocol 52te^t\right )\]
  </div>
  <div class="indent" id="1d1dad11-b010-4a66-85fd-264d84bdf4e4"> Note that choosing the arbitrary constant \(u_2\) to be nonzero is equivalent to adding a scalar
    multiple of \({\bf y}_1\) to the
    second solution \({\bf y}_2\) (Exercise&nbsp;<span class="ptmb8t-">33</span>).
  </div>
  <div class="newtheorem" id="8391dae8-2f7e-477c-a11b-584eb7fe7535">
    <div class="noindent"><span class="head">
        <span class="ex-number">Example&nbsp;10.5.3</span> </span><a id="x1-113"></a>Find the general solution of \begin
      {equation} \label {eq:10.5.7} {\bf y}'=\threebythree 34{-10}21{-2}22{-5} {\bf y}\end {equation}<a id="x1-12r7"></a>
    </div>
  </div>
  <div class="indent" id="17a26157-796a-4c68-acc7-f55ee899ce27">
  </div>
  <div class="noindent" id="dfc0aa88-ec69-4ab4-86aa-10184fcf3a72"><span class="ptmb8t-">Solution </span>&nbsp;The characteristic polynomial of the coefficient matrix
    \(A\) in (<a href="#x1-12r7">10.5.7<!-- tex4ht:ref: eq:10.5.7  --></a>) is
    \[ \left |\begin {array}{ccc} 3-\lambda &amp; 4 &amp; -10\\ 2 &amp; 1-\lambda &amp; -2\\ 2 &amp; 2 &amp;-5-\lambda
    \end {array}\right | =- (\lambda -1)(\lambda +1)^2\]
    Hence, the eigenvalues are \(\lambda _1=1\) with multiplicity&nbsp;\(1\) and \(\lambda _2=-1\) with multiplicity&nbsp;\(2\).
  </div>
  <div class="indent" id="132c1059-4edb-46bf-939c-673ff365bff8"> Eigenvectors associated with \(\lambda _1=1\) must satisfy \((A-I){\bf x}={\bf 0}\). The augmented
    matrix of this system is
    \[ \left [\begin {array}{rrrcr} 2 &amp; 4 &amp; -10 &amp;\vdots &amp; 0\\ 2&amp; 0 &amp; -2 &amp;\vdots &amp; 0\\ 2
    &amp; 2 &amp; -6 &amp; \vdots &amp; 0\end {array}\right ]\]
    which is row equivalent to



    \[ \left [\begin {array}{rrrcr} 1 &amp; 0 &amp; -1 &amp;\vdots&amp; 0\\ 0 &amp; 1 &amp; -2 &amp;\vdots&amp; 0\\ 0
    &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array}\right ]\]
    Hence, \(x_1 =x_3\) and \(x_2 =2 x_3\), where \(x_3\) is arbitrary. Choosing \(x_3=1\) yields the eigenvector
    \[ {\bf x}_1=\threecol 121\]
    Therefore
    \[ {\bf y}_1 =\threecol 121e^t \]
    is a solution of (<a href="#x1-12r7">10.5.7<!-- tex4ht:ref: eq:10.5.7  --></a>).
  </div>
  <div class="indent" id="9db26e89-4411-400d-8b9e-6274da3a786e"> Eigenvectors associated with \(\lambda _2 =-1\) satisfy \((A+I){\bf x}={\bf 0}\). The augmented
    matrix of this system is



    \[ \left [\begin {array}{rrrcr} 4 &amp; 4 &amp; -10 &amp;\vdots &amp; 0\\ 2 &amp; 2 &amp; -2 &amp; \vdots &amp; 0\\2
    &amp; 2 &amp; -4 &amp;\vdots &amp; 0\end {array}\right ]\]
    which is row equivalent to
    \[ \left [\begin {array}{rrrcr} 1 &amp; 1 &amp; 0 &amp;\vdots&amp; 0\\ 0 &amp; 0 &amp; 1 &amp;\vdots&amp; 0 \\ 0
    &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array}\right ]\]
    Hence, \(x_3=0\) and \(x_1 =-x_2\), where \(x_2\) is arbitrary. Choosing \(x_2=1\) yields the eigenvector
    \[ {\bf x}_2=\threecol {-1}10\]
    so
    \[ {\bf y}_2 =\threecol {-1}10e^{-t} \]
    is a solution of (<a href="#x1-12r7">10.5.7<!-- tex4ht:ref: eq:10.5.7  --></a>).
  </div>
  <div class="indent" id="bf0bb98a-c0aa-4aa5-9587-0032ae8c2295"> Since all the eigenvectors of \(A\) associated with \(\lambda _2=-1\) are multiples of \({\bf
    x}_2\), we must now use Theorem&nbsp;<a href="#x1-41">10.5.1<!-- tex4ht:ref: thmtype:10.5.1  --></a> to find a
    third solution of (<a href="#x1-12r7">10.5.7<!-- tex4ht:ref: eq:10.5.7  --></a>) in the form \begin {equation}
    \label {eq:10.5.8} {\bf y}_3={\bf u}e^{-t}+\threecol {-1}10te^{-t}\end {equation}<a id="x1-13r8"></a> where \(\bf
    u\) is a solution of \((A+I){\bf u=x}_2\). The augmented matrix of this system
    is



    \[ \left [\begin {array}{rrrcr} 4 &amp; 4 &amp; -10 &amp;\vdots &amp; -1\\ 2 &amp; 2 &amp; -2 &amp; \vdots &amp; 1\\
    2 &amp; 2 &amp; -4 &amp;\vdots &amp; 0\end {array}\right ]\]
    which is row equivalent to
    \[ \left [\begin {array}{rrrcr} 1 &amp; 1 &amp; 0 &amp;\vdots&amp; 1\\ 0 &amp; 0 &amp; 1 &amp;\vdots&amp; {1\over 2}
    \\ 0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array}\right ]\]
    Hence, \(u_3=1/2\) and \(u_1 =1-u_2\), where \(u_2\) is arbitrary. Choosing \(u_2=0\) yields
    \[ {\bf u} =\threecol 10{1\over 2}\]
    and substituting this into (<a href="#x1-13r8">10.5.8<!-- tex4ht:ref: eq:10.5.8  --></a>) yields the solution



    \[ {\bf y}_3=\threecol 201{e^{-t}\over 2}+\threecol {-1}10te^{-t} \]
    of (<a href="#x1-12r7">10.5.7<!-- tex4ht:ref: eq:10.5.7  --></a>).
  </div>
  <div class="indent" id="d1fdb11f-e5d0-4aa3-bfe0-8ebf6cbb2245"> Since the Wronskian of \(\{{\bf y}_1,{\bf y}_2,{\bf y}_3\}\) at \(t=0\) is
    \[ \left |\begin {array}{rrr} 1&amp;-1&amp;1\\2&amp;1&amp;0\\1&amp;0&amp;1\over 2\end {array}\right |={1\over 2}\]
    \(\{{\bf y}_1,{\bf y}_2,{\bf y}_3\}\) is a fundamental set of solutions of (<a href="#x1-12r7">10.5.7<!-- tex4ht:ref: eq:10.5.7  --></a>). Therefore the general solution of (<a href="#x1-12r7">10.5.7<!-- tex4ht:ref: eq:10.5.7  --></a>) is
    \[ {\bf y}=c_1\threecol 121e^t+c_2\threecol {-1}10e^{-t}+c_3\left (\threecol 201{e^{-t}\over 2}+\threecol
    {-1}10te^{-t}\right )\]
  </div>
  <div class="newtheorem" id="10ccf88d-a8e7-4f35-9144-5bb49b76399e">
    <div class="noindent"><span class="head">
        <span class="ptmb8t-">Theorem&nbsp;10.5.2</span> </span><a id="x1-142"></a> Suppose the
      \(n\times n\) matrix \(A\) has an eigenvalue \(\lambda
      _1\) of multiplicity \(\ge 3\) and the associated eigenspace is
        one–dimensional; that is, all eigenvectors
        associated with \(\lambda _1\) are scalar multiples of the eigenvector
      \({\bf x}.\) Then there are
        infinitely many vectors \(\bf u\) such that \begin {equation} \label
      {eq:10.5.9} (A-\lambda _1I){\bf u}={\bf x}\end {equation}<a id="x1-15r9"></a> and,
        if \(\bf u\) is any such vector, there are
        infinitely many vectors \(\bf v\) such that \begin {equation} \label
      {eq:10.5.10} (A-\lambda _1I){\bf v}={\bf u}\end {equation}<a id="x1-16r10"></a> If
      \(\bf u\)
      satisfies (<a href="#x1-15r9">10.5.9<!-- tex4ht:ref: eq:10.5.9  --></a>) and \(\bf v\) satisfies (<a href="#x1-16r10">10.5.10<!-- tex4ht:ref: eq:10.5.10  --></a>), then
    </div>
    <div class="eqnarray">\begin {eqnarray*} {\bf y}_1 &amp;=&amp;{\bf x} e^{\lambda _1t},\\ {\bf y}_2&amp;=&amp;{\bf
      u}e^{\lambda _1t}+{\bf x} te^{\lambda _1t},\mbox { and }\\ {\bf y}_3&amp;=&amp;{\bf v}e^{\lambda _1t}+{\bf
      u}te^{\lambda _1t}+{\bf x} {t^2e^{\lambda _1t}\over 2} \end {eqnarray*}</div>
    <div class="indent"> are linearly independent solutions of \({\bf y}'=A{\bf y}\).
    </div>
  </div>
  <div class="indent" id="7ee25c59-eb94-4486-b026-36272afc1247">
  </div>
  <div class="indent" id="583f90a2-820b-4e69-ac03-d021c666a43f"> Again, it’s beyond the scope of this book to prove that there are vectors \(\bf u\) and \(\bf v\)
    that satisfy (<a href="#x1-15r9">10.5.9<!-- tex4ht:ref: eq:10.5.9  --></a>) and
    (<a href="#x1-16r10">10.5.10<!-- tex4ht:ref: eq:10.5.10  --></a>). Theorem&nbsp;<a href="#x1-41">10.5.1<!-- tex4ht:ref: thmtype:10.5.1  --></a> implies that \({\bf y}_1\) and \({\bf y}_2\) are
    solutions of \({\bf y}'=A{\bf y}\). We leave the rest of the proof to you
    (Exercise&nbsp;<span class="ptmb8t-">34</span>).
  </div>
  <div class="newtheorem" id="59bbd33a-8911-483f-9c94-cf32ab90d1bf">
    <div class="noindent"><span class="head">



        <span class="ex-number">Example&nbsp;10.5.4</span> </span><a id="x1-174"></a>Use Theorem&nbsp;<a href="#x1-142">10.5.2<!-- tex4ht:ref: thmtype:10.5.2  --></a> to find the general solution of \begin {equation}
      \label {eq:10.5.11} {\bf y}'=\threebythree 11113{-1}022{\bf y}\end {equation}<a id="x1-18r11"></a>
    </div>
  </div>
  <div class="indent" id="d3934eeb-89de-42f0-acc8-ca2349908113">
  </div>
  <div class="noindent" id="916fc953-73e5-4ac9-967b-9f3bd96fe75d"><span class="ptmb8t-">Solution </span>&nbsp;The characteristic polynomial of the coefficient matrix
    \(A\) in (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>) is
    \[ \left |\begin {array}{ccc} 1-\lambda &amp; 1 &amp; \phantom {-}1\\ 1 &amp; 3-\lambda &amp; -1\\ 0 &amp; 2 &amp;
    2-\lambda \end {array}\right | =-(\lambda -2)^3\]
    Hence, \(\lambda _1=2\) is an eigenvalue of multiplicity \(3\). The associated eigenvectors satisfy \((A-2I){\bf
    x=0}\). The augmented matrix of this
    system is
    \[ \left [\begin {array}{rrrcr} -1 &amp; 1 &amp; 1 &amp;\vdots &amp; 0\\ 1&amp; 1 &amp; -1 &amp;\vdots &amp; 0\\ 0
    &amp; 2 &amp; 0 &amp; \vdots &amp; 0\end {array}\right ]\]
    which is row equivalent to
    \[ \left [\begin {array}{rrrcr} 1 &amp; 0 &amp;- 1 &amp;\vdots&amp; 0\\ 0 &amp; 1 &amp; 0 &amp;\vdots&amp; 0 \\ 0
    &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array}\right ]\]
    Hence, \(x_1 =x_3\) and \(x_2 = 0\), so the eigenvectors are all scalar multiples of



    \[ {\bf x}_1=\threecol 101\]
    Therefore
    \[ {\bf y}_1=\threecol 101e^{2t} \]
    is a solution of (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>).
  </div>
  <div class="indent" id="b4c89322-f71a-4edf-bc83-c67dfaebfa8d"> We now find a second solution of (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>)
    in the form
    \[ {\bf y}_2={\bf u}e^{2t}+\threecol 101te^{2t}\]
    where \(\bf u\) satisfies \((A-2I){\bf u=x}_1\). The augmented matrix of this system is



    \[ \left [\begin {array}{rrrcr} -1 &amp; 1 &amp; 1 &amp;\vdots &amp; 1\\ 1&amp; 1 &amp; -1 &amp;\vdots &amp; 0\\ 0
    &amp; 2 &amp; 0 &amp; \vdots &amp; 1\end {array}\right ]\]
    which is row equivalent to
    \[ \left [\begin {array}{rrrcr} 1 &amp; 0 &amp;- 1 &amp;\vdots&amp; -{1\over 2}\\ 0 &amp; 1 &amp; 0 &amp;\vdots&amp;
    {1\over 2}\\ 0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array}\right ]\]
    Letting \(u_3=0\) yields \(u_1=-1/2\) and \(u_2=1/2\); hence,
    \[ {\bf u}={1\over 2}\threecol {-1}10 \]
    and
    \[ {\bf y}_2=\threecol {-1}10{e^{2t}\over 2}+\threecol 101te^{2t} \]
    is a solution of (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>).
  </div>
  <div class="indent" id="c76eaf4a-15dc-46ee-b92b-739df7daccfd"> We now find a third solution of (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>)
    in the form



    \[ {\bf y}_3={\bf v}e^{2t}+\threecol {-1}10{te^{2t}\over 2}+\threecol 101{t^2e^{2t}\over 2} \]
    where \(\bf v\) satisfies \((A-2I){\bf v}={\bf u}\). The augmented matrix of this system is
    \[ \left [\begin {array}{rrrcr} -1 &amp; 1 &amp; 1 &amp;\vdots &amp;-{1\over 2}\\ 1&amp; 1 &amp; -1 &amp;\vdots
    &amp; {1\over 2}\\ 0 &amp; 2 &amp; 0 &amp; \vdots &amp; 0\end {array}\right ]\]
    which is row equivalent to
    \[ \left [\begin {array}{rrrcr} 1 &amp; 0 &amp;- 1 &amp;\vdots&amp; {1\over 2}\\ 0 &amp; 1 &amp; 0 &amp;\vdots&amp;
    0\\ 0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array}\right ]\]
    Letting \(v_3=0\) yields \(v_1=1/2\) and \(v_2=0\); hence,



    \[ {\bf v}={1\over 2}\threecol 100\]
    Therefore
    \[ {\bf y}_3=\threecol 100{e^{2t}\over 2}+ \threecol {-1}10{te^{2t}\over 2}+\threecol 101{t^2e^{2t}\over 2} \]
    is a solution of (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>). Since \({\bf y}_1\), \({\bf
    y}_2\), and \({\bf y}_3\) are linearly independent by Theorem&nbsp;<a href="#x1-142">10.5.2<!-- tex4ht:ref: thmtype:10.5.2  --></a>, they form a fundamental set
    of solutions of (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>). Therefore the general solution of
    (<a href="#x1-18r11">10.5.11<!-- tex4ht:ref: eq:10.5.11  --></a>) is </div>
  <div class="eqnarray" id="c46f4f8d-6d94-432a-9f76-28def8239081">\begin {eqnarray*} {\bf y} &amp;=&amp;\displaystyle {c_1\threecol 101e^{2t}+ c_2\left (\threecol
    {-1}10{e^{2t}\over 2}+\threecol 101te^{2t}\right )}\\ &amp;&amp;+c_3\displaystyle {\left (\threecol 100{e^{2t}\over
    2}+ \threecol {-1}10{te^{2t}\over 2}+\threecol 101{t^2e^{2t}\over 2}\right )}\end {eqnarray*}</div>
  <div class="newtheorem" id="1442ee02-5619-4fb7-9096-46c3932525df">
    <div class="noindent"><span class="head">
        <span class="ptmb8t-">Theorem&nbsp;10.5.3</span> </span><a id="x1-193"></a> Suppose the
      \(n\times n\) matrix \(A\) has an eigenvalue \(\lambda
      _1\) of multiplicity \(\ge 3\) and the associated eigenspace
        is
        two–dimensional; that is, all eigenvectors of \(A\) associated with
      \(\lambda _1\) are linear combinations of two linearly
        independent eigenvectors \({\bf x}_1\) and \({\bf x}_2\)\(.\) Then there are constants \(\alpha \) and \(\beta \)
      \((\)not both zero\()\) such that if \begin {equation}
      \label {eq:10.5.12} {\bf x}_3=\alpha {\bf x}_1+\beta {\bf x}_2\end {equation}<a id="x1-20r12"></a> then there are infinitely
        many vectors \(\bf u\) such that \begin {equation} \label {eq:10.5.13}
      (A-\lambda _1I){\bf u}={\bf x}_3\end {equation}<a id="x1-21r13"></a> If \(\bf u\)
      satisfies (<a href="#x1-21r13">10.5.13<!-- tex4ht:ref: eq:10.5.13  --></a>), then </div>
    <div class="eqnarray">\begin {eqnarray} {\bf y}_1&amp;=&amp;{\bf x}_1 e^{\lambda _1t},\nonumber \\ {\bf
      y}_2&amp;=&amp;{\bf x}_2e^{\lambda _1t},\mbox {and }\nonumber \\ {\bf y}_3&amp;=&amp;{\bf u}e^{\lambda _1t}+{\bf
      x}_3te^{\lambda _1t}\label {eq:10.5.14}\end {eqnarray}</div>
    <div class="indent"> are linearly independent solutions of \({\bf y}'=A{\bf y}.\)
    </div>
  </div>
  <div class="indent" id="6aa87db9-2aac-44d0-a1bb-9ee80ccd23af">
  </div>
  <div class="indent" id="0e77b935-a80d-4a5b-96e2-04a5118509fe"> We omit the proof of this theorem.
  </div>
  <div class="indent" id="337de6ff-f338-4026-ba5f-2569f72fee1f">



  </div>
  <div class="newtheorem" id="2bba3cf4-7664-458e-b8c1-f8627d54584c">
    <div class="noindent"><span class="head">
        <span class="ex-number">Example&nbsp;10.5.5</span> </span><a id="x1-225"></a>Use Theorem&nbsp;<a href="#x1-193">10.5.3<!-- tex4ht:ref: thmtype:10.5.3  --></a> to find the general solution of \begin {equation}
      \label {eq:10.5.15} {\bf y}'=\threebythree 001{-1}11{-1}02{\bf y}\end {equation}<a id="x1-23r14"></a>
    </div>
  </div>
  <div class="indent" id="c4322915-e0a6-4e7b-9ebd-cf941ac45f93">
  </div>
  <div class="noindent" id="74f0d720-8527-4017-87ea-12fe6bf86f90"><span class="ptmb8t-">Solution </span>&nbsp;The characteristic polynomial of the coefficient matrix
    \(A\) in (<a href="#x1-23r14">10.5.15<!-- tex4ht:ref: eq:10.5.15  --></a>) is
    \[ \left |\begin {array}{ccc} -\lambda &amp; 0 &amp; 1\\ -1 &amp; 1-\lambda &amp; 1\\ -1 &amp; 0 &amp; 2-\lambda
    \end {array}\right | =-(\lambda -1)^3\]
    Hence, \(\lambda _1=1\) is an eigenvalue of multiplicity \(3\). The associated eigenvectors satisfy \((A-I){\bf
    x=0}\). The augmented matrix of this
    system is
    \[ \left [\begin {array}{rrrcr} -1 &amp; 0 &amp; 1 &amp;\vdots &amp; 0\\ -1&amp; 0 &amp; 1 &amp;\vdots &amp; 0\\ -1
    &amp; 0 &amp; 1 &amp; \vdots &amp; 0\end {array}\right ]\]
    which is row equivalent to



    \[ \left [\begin {array}{rrrcr} 1 &amp; 0 &amp;- 1 &amp;\vdots&amp; 0\\ 0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0 \\ 0
    &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array}\right ]\]
    Hence, \(x_1 =x_3\) and \(x_2\) is arbitrary, so the eigenvectors are of the form
    \[ {\bf x}_1=\threecol {x_3}{x_2}{x_3}=x_3\threecol 101+x_2\threecol 010\]
    Therefore the vectors \begin {equation} \label {eq:10.5.16} {\bf x}_1 =\threecol 101\quad \mbox {and }\quad {\bf
    x}_2=\threecol 010 \end {equation}<a id="x1-24r15"></a> form a basis for the eigenspace, and
    \[ {\bf y}_1 =\threecol 101e^t\quad \mbox {and }\quad {\bf y}_2=\threecol 010e^t \]
    are linearly independent solutions of (<a href="#x1-23r14">10.5.15<!-- tex4ht:ref: eq:10.5.15  --></a>).
  </div>
  <div class="indent" id="4f689663-4397-4216-859b-f0ae914aa755"> To find a third linearly independent solution of (<a href="#x1-23r14">10.5.15<!-- tex4ht:ref: eq:10.5.15  --></a>), we must find constants \(\alpha \) and \(\beta \)
    (not both zero) such that
    the system \begin {equation} \label {eq:10.5.17} (A-I){\bf u}=\alpha {\bf x}_1+\beta {\bf x}_2 \end {equation}<a id="x1-25r16"></a> has a solution \(\bf u\). The augmented matrix of this system is
    \[ \left [\begin {array}{rrrcr} -1 &amp; 0 &amp; 1 &amp;\vdots &amp;\alpha \\ -1&amp; 0 &amp; 1 &amp;\vdots
    &amp;\beta \\ -1 &amp; 0 &amp; 1 &amp; \vdots &amp;\alpha \end {array}\right ]\]
    which is row equivalent to \begin {equation} \label {eq:10.5.18} \left [\begin {array}{rrrcr} 1 &amp; 0 &amp;- 1
    &amp;\vdots &amp; -\alpha \\ 0 &amp; 0 &amp; 0 &amp;\vdots &amp;\beta -\alpha \\ 0 &amp; 0 &amp; 0 &amp;\vdots
    &amp;0\end {array} \right ]\end {equation}<a id="x1-26r17"></a> Therefore (<a href="#x1-25r16">10.5.17<!-- tex4ht:ref: eq:10.5.17  --></a>) has a solution if and only if \(\beta =\alpha \),
    where \(\alpha \) is arbitrary. If \(\alpha =\beta =1\) then (<a href="#x1-20r12">10.5.12<!-- tex4ht:ref: eq:10.5.12  --></a>)
    and (<a href="#x1-24r15">10.5.16<!-- tex4ht:ref: eq:10.5.16  --></a>) yield



    \[ {\bf x}_3={\bf x}_1+{\bf x}_2= \threecol 101+\threecol 010=\threecol 111\]
    and the augmented matrix (<a href="#x1-26r17">10.5.18<!-- tex4ht:ref: eq:10.5.18  --></a>) becomes
    \[ \left [\begin {array}{rrrcr} 1 &amp; 0 &amp;- 1 &amp;\vdots&amp; -1\\ 0 &amp; 0 &amp; 0 &amp;\vdots&amp; 0\\ 0
    &amp; 0 &amp; 0 &amp;\vdots&amp; 0\end {array} \right ]\]
    This implies that \(u_1=-1+u_3\), while \(u_2\) and \(u_3\) are arbitrary. Choosing \(u_2=u_3=0\) yields
    \[ {\bf u}=\threecol {-1}00\]
    Therefore (<span class="ptmb8t-">10.5.14</span>) implies that



    \[ {\bf y}_3={\bf u}e^t+{\bf x}_3te^t=\threecol {-1}00e^t+\threecol 111te^t \]
    is a solution of (<a href="#x1-23r14">10.5.15<!-- tex4ht:ref: eq:10.5.15  --></a>). Since \({\bf y}_1\), \({\bf
    y}_2\), and \({\bf y}_3\) are linearly independent by Theorem&nbsp;<a href="#x1-193">10.5.3<!-- tex4ht:ref: thmtype:10.5.3  --></a>, they form a fundamental set
    of solutions for (<a href="#x1-23r14">10.5.15<!-- tex4ht:ref: eq:10.5.15  --></a>). Therefore the general solution
    of (<a href="#x1-23r14">10.5.15<!-- tex4ht:ref: eq:10.5.15  --></a>) is
    \[ {\bf y}=c_1\threecol 101e^t+c_2\threecol 010e^t +c_3\left (\threecol {-1}00e^t+\threecol 111te^t\right )\]
  </div>
  <div class="noindent" id="ef5d1188-eb27-4fdf-a437-e65d53b6d0ab"><span id="textcolor1">Geometric Properties of Solutions when \(n=2\)</span>
  </div>
  <div class="indent" id="93f75e3e-9ad2-4f3c-8b75-d4dde19b3835">
  </div>
  <div class="noindent" id="f4ad3e08-7ca5-4d6b-b631-a71d4c46bceb">We’ll now consider the geometric properties of solutions of a \(2\times 2\) constant coefficient
    system \begin {equation} \label {eq:10.5.19} \twocol {y_1'}{y_2'}=\left [\begin
    {array}{cc}a_{11}&amp;a_{12}\\a_{21}&amp;a_{22} \end {array}\right ]\twocol {y_1}{y_2} \end {equation}<a id="x1-27r18"></a> under the assumptions
    of this section; that is, when the matrix
    \[ A=\left [\begin {array}{cc}a_{11}&amp;a_{12}\\a_{21}&amp;a_{22} \end {array}\right ] \]
    has a repeated eigenvalue \(\lambda _1\) and the associated eigenspace is one-dimensional. In this case we know from
    Theorem&nbsp;<a href="#x1-41">10.5.1<!-- tex4ht:ref: thmtype:10.5.1  --></a> that the general solution of (<a href="#x1-27r18">10.5.19<!-- tex4ht:ref: eq:10.5.19  --></a>) is \begin {equation} \label {eq:10.5.20} {\bf
    y}=c_1{\bf x}e^{\lambda _1t}+c_2({\bf u}e^{\lambda _1t}+{\bf x}te^{\lambda _1t})\end {equation}<a id="x1-28r19"></a>
    where \(\bf x\) is an eigenvector of \(A\) and \(\bf u\) is any one of the
    infinitely many solutions of \begin {equation} \label {eq:10.5.21} (A-\lambda _1I){\bf u}={\bf x}\end {equation}<a id="x1-29r20"></a> We assume that \(\lambda _1\ne 0\).
  </div>
  <figure class="figure" id="dea537ec-fee0-4478-aa49-aa15d876e31b">







    <div class="noindent" id="-positive-and-negative-halfplanes-"> <img height="264" src="EPS/fig100501.png" width="409"><a id="x1-30r1"></a></div>
    <figcaption class="caption"><span class="id">Figure&nbsp;10.5.1 </span><span class="content">Positive and negative
        half-planes </span></figcaption><!-- tex4ht:label?: x1-30r1  -->



  </figure>
  <div class="indent" id="7c9f4988-6c87-4480-90a9-f2e2cc357091"> Let \(L\) denote the line through the origin parallel to \(\bf x\). By a <span class="vocab">half-line</span> of \(L\) we mean either of the rays obtained by
    removing the origin from \(L\). Eqn.&nbsp;(<a href="#x1-28r19">10.5.20<!-- tex4ht:ref: eq:10.5.20  --></a>) is a
    parametric equation of the half-line of \(L\) in the direction of \(\bf x\)
    if \(c_1&gt;0\), or of the half-line of \(L\) in the direction of \(-{\bf x}\) if \(c_1&lt;0\). The origin is the
    trajectory of the trivial solution
    \({\bf y}\equiv {\bf 0}\).
  </div>
  <div class="indent" id="b0049e05-89df-4a91-a360-d99fdad08439"> Henceforth, we assume that \(c_2\ne 0\). In this case, the trajectory of (<a href="#x1-28r19">10.5.20<!-- tex4ht:ref: eq:10.5.20  --></a>) can’t intersect \(L\), since every point of \(L\) is
    on
    a trajectory obtained by setting \(c_2=0\). Therefore the trajectory of (<a href="#x1-28r19">10.5.20<!-- tex4ht:ref: eq:10.5.20  --></a>) must lie entirely in one of the open
    half-planes bounded by \(L\), but does not contain any point on \(L\). Since the initial point \((y_1(0),y_2(0))\)
    defined by \({\bf y}(0)=c_1{\bf x}_1+c_2{\bf u}\) is on the trajectory,
    we can determine which half-plane contains the trajectory from the sign of \(c_2\), as shown in Figure&nbsp;<a href="#-positive-and-negative-halfplanes-">10.5.1<!-- tex4ht:ref: thmtype:10.5.1  --></a>. For
    convenience we’ll call the half-plane where \(c_2&gt;0\) the <span class="vocab">positive half-plane</span>.
    Similarly, the-half plane where \(c_2&lt;0\) is the
    <span class="vocab">negative half-plane</span>. You should convince yourself (Exercise&nbsp;<span class="ptmb8t-">35</span>) that even though there are infinitely many
    vectors \(\bf u\) that satisfy (<a href="#x1-29r20">10.5.21<!-- tex4ht:ref: eq:10.5.21  --></a>), they all define
    the same positive and negative half-planes. In the figures
    simply regard \(\bf u\) as an arrow pointing to the positive half-plane, since wen’t attempted to give \(\bf u\) its
    proper length or direction in comparison with \(\bf x\). For our purposes here, only the relative orientation of
    \(\bf x\)
    and \(\bf u\) is important; that is, whether the positive half-plane is to the right of an observer facing the
    direction of \(\bf x\) (as in Figures&nbsp;<a href="#-positive-eigenvalue-motion-away-from-the-origin-">10.5.2<!-- tex4ht:ref: figure:10.5.2  --></a> and <a href="#-negative-eigenvalue-motion-toward-the-origin-1">10.5.5<!-- tex4ht:ref: figure:10.5.5  --></a>), or to the
    left of the observer (as in Figures&nbsp;<a href="#-positive-eigenvalue-motion-away-from-the-origin-1">10.5.3<!-- tex4ht:ref: figure:10.5.3  --></a> and
    <a href="#-negative-eigenvalue-motion-toward-the-origin-">10.5.4<!-- tex4ht:ref: figure:10.5.4  --></a>).
  </div>
  <div class="indent" id="bfd9ae01-6e16-4ba0-b2a9-ce6183c9f27b"> Multiplying (<a href="#x1-28r19">10.5.20<!-- tex4ht:ref: eq:10.5.20  --></a>) by \(e^{-\lambda
    _1t}\) yields
    \[ e^{-\lambda _1t}{\bf y}(t)=c_1{\bf x}+c_2{\bf u}+c_2t {\bf x}\]
    Since the last term on the right is dominant when \(|t|\) is large, this provides the following information on the
    direction of \({\bf y}(t)\):
  </div>
  <dl class="list1" id="508dfe64-05de-4c47-b4d0-676c5cbe9c92">
    <dt class="list">
      <span class="ptmb8t-">(a)</span>
    </dt>
    <dd class="list">
      <div class="noindent">Along trajectories in the positive half-plane (\(c_2&gt;0\)), the direction of \({\bf y}(t)\)
        approaches the direction of \(\bf x\) as \(t\to \infty \) and
        the direction of \(-{\bf x}\) as \(t\to -\infty \).
      </div>
    </dd>
    <dt class="list">
      <span class="ptmb8t-">(b)</span>
    </dt>
    <dd class="list">
      <div class="noindent">Along trajectories in the negative half-plane (\(c_2&lt;0\)), the direction of \({\bf y}(t)\)
        approaches the direction of \(-{\bf x}\) as \(t\to \infty \) and
        the direction of \(\bf x\) as \(t\to -\infty \).</div>
    </dd>
  </dl>
  <div class="indent" id="85b1a7c4-89d1-437b-90bd-254332255999"> Since



    \[ \lim _{t\to \infty }\|{\bf y}(t)\|=\infty \quad \mbox{ and } \quad  \lim _{t\to -\infty }{\bf y}(t)={\bf 0}\quad \mbox{ if } \quad \lambda _1&gt;0\]
    or
    \[ \lim _{t-\to \infty }\|{\bf y}(t)\|=\infty \quad \mbox{ and } \quad  \lim _{t\to \infty }{\bf y}(t)={\bf 0}\quad \mbox{ if } \quad \lambda _1&lt;0\]
    there are four possible patterns for the trajectories of (<a href="#x1-27r18">10.5.19<!-- tex4ht:ref: eq:10.5.19  --></a>), depending upon the signs of \(c_2\) and \(\lambda
    _1\).
    Figures&nbsp;<a href="#-positive-eigenvalue-motion-away-from-the-origin-">10.5.2<!-- tex4ht:ref: figure:10.5.2  --></a>-<a href="#-negative-eigenvalue-motion-toward-the-origin-1">10.5.5<!-- tex4ht:ref: figure:10.5.5  --></a> illustrate
    these patterns, and reveal the following principle:
  </div>
  <div class="indent" id="5305bb2c-1096-46c9-9791-e02ac87628c2"> If \(\lambda _1\) and \(c_2\) have the same sign then the direction of the traectory approaches the direction of \(-{\bf
    x}\) as \(\|{\bf y} \|\to 0\) and the direction
      of \(\bf x\) as \(\|{\bf y}\|\to \infty \). If
    \(\lambda _1\) and \(c_2\) have opposite signs then the
      direction of the trajectory approaches the direction of \(\bf x\) as \(\|{\bf
    y} \|\to 0\) and the
      direction of \(-{\bf x}\) as \(\|{\bf y}\|\to \infty \).
  </div>
  <figure class="figure" id="f5cba2c3-03e1-443b-bfbf-a785c7152617">







    <div class="minipage">
      <div class="noindent" id="-positive-eigenvalue-motion-away-from-the-origin-"> <img height="264" src="EPS/fig100502.png" width="409"><a id="x1-33r2"></a></div>
      <figcaption class="caption"><span class="id">Figure&nbsp;10.5.2 </span><span class="content">Positive eigenvalue;
          motion away
          from the origin </span></figcaption><!-- tex4ht:label?: x1-33r2  -->
    </div>
    <div class="minipage" id="-positive-eigenvalue-motion-away-from-the-origin-1"> <img height="264" src="EPS/fig100503.png" width="409"> <a id="x1-34r3"></a>
      <figcaption class="caption"><span class="id">Figure&nbsp;10.5.3 </span><span class="content">Positive eigenvalue;
          motion away
          from the origin </span></figcaption><!-- tex4ht:label?: x1-34r3  -->
    </div>
  </figure>
  <figure class="figure" id="a520291e-2d0c-4c40-93e0-a01f903a7038">
    <div class="minipage">
      <div class="noindent" id="-negative-eigenvalue-motion-toward-the-origin-"> <img height="264" src="EPS/fig100504.png" width="409"><a id="x1-35r4"></a></div>
      <figcaption class="caption"><span class="id">Figure&nbsp;10.5.4 </span><span class="content">Negative eigenvalue;
          motion toward
          the origin </span></figcaption><!-- tex4ht:label?: x1-35r4  -->
    </div>
    <div class="minipage" id="-negative-eigenvalue-motion-toward-the-origin-1"> <img height="264" src="EPS/fig100505.png" width="409"> <a id="x1-36r5"></a>
      <figcaption class="caption"><span class="id">Figure&nbsp;10.5.5 </span><span class="content">Negative eigenvalue;
          motion toward
          the origin </span></figcaption><!-- tex4ht:label?: x1-36r5  -->
    </div>
  </figure>
  <div class="indent" id="3ff10533-88d0-4f68-a74a-28deb4b02f89">
  </div>

  
  <div class="nav" id="0cd08f07-399e-4f08-b6cf-859274323828">
    <a href="sec10.4.book.html">Back (10.4)</a>

    <a href="sec10.0.html">Chapter 10</a>

    <a href="sec10.6.book.html">Next (10.6)</a>
  </div>



</body></html>